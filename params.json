{"name":"NSString-Japanese","tagline":"NSString category methods for working with Japanese strings","body":" The Language Loupe\r\n=\r\n\r\nA text magnification loupe normally appears when you press and drag over text in iOS.  In this example we’re going to not only recreate the loupe that appears but also change what it magnifies.\r\n\r\n![Alt text](https://raw.github.com/works5/NSString-Japanese/gh-pages/screenShot1.jpg \"Screenshot\")\r\n\r\nNSString-Japanese\r\n=\r\n\r\nThere is some really awesome stuff in Foundation and [CFStringTokenizer](https://developer.apple.com/library/ios/DOCUMENTATION/CoreFoundation/Reference/CFStringTokenizerRef/Reference/reference.html) is one of them. With CFStringTokenizer you can determine the language of an arbitrary sentence, obtain the latin script of a language (such as Japanese) and enumerate words in sentences in languages that don’t delimit words by space.\r\n\r\nJapanese writing is composed of Kanji, Hiragana, and Katakana. The latin transcription of Japanese is Romaji. \r\n\r\nTo obtain the Romaji for a given string, you create a CFStringTokenizer instance with the string, enumerate over each token and request the latin attributes for each token. \r\n\r\nThe NSString-Japanese categories reduce these steps to one line and are the focus of this repository. You can look at source implementation to see how you might use CFStringTokenizer for another language or in other ways.\r\n\r\n\r\nThe Loupe\r\n=\r\n\r\nThe loupe is simply a custom UIView with three important features. Our custom view contains a UIImageView subview,  a  content view to magnify, and rectangle region within the content view to magnify.  These features enable us to present the glass image, and draw dynamic contents for the loupe.\r\n\r\nLet’s look at the drawRect implementation.\r\n\r\n    -(void)drawRect:(CGRect)rect{\r\n    \r\n        if(!_loupeContentView)\r\n            return;\r\n\r\n\t    CGContextRef context = UIGraphicsGetCurrentContext();\r\n        CGContextClearRect(context,rect);\r\n\r\n        UIBezierPath* bPath = [UIBezierPath bezierPathWithOvalInRect:CGRectInset(rect,7,7)];\r\n\r\n\t    CGContextAddPath(context,bPath.CGPath);\r\n        CGContextClip(context);\r\n    \r\n\t    CGContextTranslateCTM(context, -_loupeContentRect.origin.x, -_loupeContentRect.origin.y);\r\n\t    [_loupeContentView.layer renderInContext:context];\r\n    \r\n    }\r\n\r\n\r\n* We get the current context and clear it.\r\n* Create circular path(the shape of the loupe glass), add the path to the context, and clip the context.   This essentially restricts drawing to the path of the circle.\r\n* We flip the coordinates (for CoreGraphics) and finally draw contents of the contentView in our clipped context.\r\n\r\nIf you wanted to  magnify the contents of the loupe, you would simply scale the context before rendering loupe contents in the graphics context.\r\n\r\n\r\nBack off UIKit\r\n=\r\n\r\nBy default in UIKit presents its own loupe view when the user presses over text.  To prevent this, it is useful to remember that UIApplication sends events to the window first and that UIWindow is a subclass of UIView. We can alter default behavior by overriding UIWindow’s hitTest method. So we subclass UIWindow and create a hitTestDelegate to gain greater control.  This is will let us control when we want  the UIKit’s controls to appear or not.*\r\n\r\n\r\nHere’s the implementation of our new hitTest method in our new window subclass.\r\n\r\n    -(UIView*)hitTest:(CGPoint)point withEvent:(UIEvent *)event{\r\n \r\n        UIView* original = [super hitTest:point withEvent:event];\r\n    \r\n    \tif([self.hitTestDelegate respondsToSelector:@selector(viewForHitTest:withPoint:event:andOriginalView:)])\r\n        \treturn [self.hitTestDelegate viewForHitTest:self withPoint:point event:event andOriginalView:original];\r\n    \r\n    \r\n    \treturn original;\r\n\t}\r\n\r\n* We call super and keep a reference to the view that UIKit would like to return.\r\n* We return the result of our own hitTestDelegate method.\r\n\r\nI’ve implemented this hitTestDelegate  in our demoView Controller. Here’s that implementation.\r\n\r\n\t-(UIView*)viewForHitTest:(SLGDemoWindow*)window withPoint:(CGPoint)point event:(UIEvent*)event andOriginalView:(UIView*)originalView{\r\n    \r\n    \tif(_textView.editable)\r\n        \treturn originalView;\r\n    \r\n    \tif(!_languageLoupeSwitch.on)\r\n        \treturn originalView;\r\n    \r\n    \tif([originalView isDescendantOfView:_textView]){\r\n        \treturn self.view;\r\n    \t}\r\n    \treturn originalView;\r\n\t}\r\n\r\n* If the text view instance is editable or if our custom language loupe is disabled we simply return the original view intended by UIKit.\r\n* If the originalView that UIKit returned from its hitTest is a subview of UITextView or the UITextView itself, then we return our viewController’s view. Our viewController’s view has a  press gesture attached to it and can respond accordingly.**\r\n\r\n \r\nSlight of hand\r\n=\r\n\r\nInstead of displaying of the original textView inside the loupe, we’ll display the selected Japanese text but converted to Romaji or Hiragana.\r\nTo accomplish this, we create another textview and insert it behind the visible textView. We assign our ‘secret’ textView to our custom loupe view. The loupe view will render ‘secret’ textView contents instead of the visible textView.\r\n\r\nThere are lot of steps to updating contents of the loupeView. Let’s walk through them\r\n\r\n    -(void)_updateLoupeWithPoint:(CGPoint)point{\r\n\r\n    \r\n        UITextPosition* pos = [self.visibleTextView closestPositionToPoint:point];\r\n    \r\n        id<UITextInputTokenizer> tokenizer =self.visibleTextView.tokenizer;\r\n        UITextRange* textRange =\r\n        [tokenizer rangeEnclosingPosition:pos\r\n                          withGranularity:UITextGranularityWord\r\n                              inDirection:UITextWritingDirectionLeftToRight];\r\n    \r\n        if(!textRange)\r\n            return;\r\n    \r\n         NSRange wordRange = [[self class]rangeForTextRange:textRange inTextView:self.visibleTextView];\r\n    \r\n\r\n\r\n        CGRect caretRect= [self.visibleTextView caretRectForPosition:pos];\r\n    \r\n        CGRect loupeFrame;\r\n        loupeFrame.size = _loupeView.glassSize;\r\n        loupeFrame.origin = [self.view convertPoint:caretRect.origin fromView:self.visibleTextView];\r\n        loupeFrame = CGRectOffset(loupeFrame,-loupeFrame.size.width/2,(-loupeFrame.size.height+10));\r\n    \r\n\r\n    \r\n        NSRange convertedRange;\r\n        [self _updateSecretTextViewTextWithRange:wordRange convertedRange:&convertedRange];\r\n    \r\n    \r\n        UIBezierPath* magnifyPath = [[self class]pathForRange:convertedRangeinTextView:self.secretTextView];\r\n        CGRect rectToMagnify;\r\n        rectToMagnify.size =_loupeView.glassSize;\r\n        rectToMagnify.origin = CGPathGetBoundingBox(magnifyPath.CGPath).origin;\r\n        rectToMagnify  = CGRectOffset(rectToMagnify,-rectToMagnify.size.width/2,(-rectToMagnify.size.height/2.5));\r\n    \r\n\r\n        [CATransaction setDisableActions:YES];\r\n        _textViewSelectionLayer.path = [[self class]pathForRange:wordRange inTextView:self.visibleTextView].CGPath;\r\n        _outputSelectionLayer.path = magnifyPath.CGPath;\r\n        [CATransaction commit];\r\n\r\n\r\n        _loupeView.loupeContentRect = rectToMagnify;\r\n        _loupeView.frame =loupeFrame;\r\n        [_loupeView setNeedsDisplay];\r\n    \r\n\r\n    \r\n    }\r\n\r\n* Note that the updateLoupeWithPoint: method is passed a point in the ‘visible’ textView’s coordinate space from the press gesture.\r\n* Calculate the NSRange of the word closest to the point in the string contents of the ‘visible’ textView. \r\n* Calculate the loupe frame using the size of the loupeView glassImage and position of the selected word.\r\n* Update the contents of the ‘secret’ textView to reflect the selected text changes.\r\n* Use the range of the word converted (to Romaji or Hiragana) to calculate the rectangle contents of the loupeView.\r\n* Update the fill paths of our ‘fake’ selection layers. I’ve inserted 2 CAShapeLayers into each of these textViews. Adding a subview to a UITextView doesn’t play well with UITextView internals. But adding CALayer to it’s sublayer works well enough. This is allows us to mimic the some of selection interface that UIKit presents.***\r\n\r\n\r\n*Another approach would be to subclass UITextView and override the hitTest implementation and handle the logic (via delegation or internally) as well.  \r\n\r\n**The subviews of UITextView (UITextRangeView and UISelectionGrabber) are private classes so [UIView isDescendantOfView] is a good candidate for checking without explicitly referring to those classes.\r\n\r\n***The demo ViewController contains some methods around calculating the text positions and paths. There’s a much more complete set of methods located [here](https://github.com/works5/UITextViewExtras).\r\n\r\nFinal Thoughts\r\n=\r\nWhile this pretty cool effect, admittedly it’s not perfect. There are issues with word wrapping in the secret textView, the glass image, and the selected text is sometimes clipped. Perhaps the clipping issue could be addressed with a bit more math and using a resizable image inside the loupeView.\r\n\r\nThanks for reading!","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}